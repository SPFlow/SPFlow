{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developer Guide\n",
    "\n",
    "This guide describes how to extend the SpFlow library, including adding custom leaf modules with new distributions, implementing variations of sum or product modules, and developing alternative utility modules such as new split modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaf Modules\n",
    "\n",
    "In this section, we demonstrate how to implement a new leaf module with a custom distribution. As an example, we use a simple toy distribution defined over the range `[-10, 10]`. It includes one trainable parameter, **border**, which divides the domain into “likely’’ and “unlikely’’ regions:\n",
    "\n",
    "- values in the interval `[border, 10]` have probability **0.7**,  \n",
    "- values in `[-10, border)` have probability **0.3**.\n",
    "\n",
    "Although this is not a probabilistically valid distribution (e.g., its probabilities do not integrate to 1), it is sufficient to illustrate how to construct a custom leaf module.\n",
    "\n",
    "The `CustomLeaf` class inherits from `LeafModule`, the base class for all leaf modules. Consequently, all initialization parameters required by `LeafModule` must also be included in the subclass constructor, in addition to any distribution-specific parameters. For a normal distribution, these parameters might be `loc` and `scale`; in our custom example, the required parameter is the trainable **border**. Once included, this parameter can be initialized just like any other PyTorch parameter.\n",
    "\n",
    "The only methods that must be implemented manually are the helper functions used for **maximum likelihood estimation**. The base `LeafModule` handles all remaining functionality.\n",
    "\n",
    "Custom leaf distributions should follow the structure of a standard PyTorch distribution. Therefore, if your distribution is not derived from an existing PyTorch distribution class, you must implement the distribution logic and all required methods yourself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from spflow.modules.leaves.base import LeafModule\n",
    "from spflow.utils.leaves import init_parameter, _handle_mle_edge_cases\n",
    "\n",
    "\n",
    "class CustomLeaf(LeafModule):\n",
    "    \"\"\"Custom distribution leaf module.\n",
    "\n",
    "    Parameterized by border.\n",
    "\n",
    "    Attributes:\n",
    "        border: Border that separates the value interval.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        scope,\n",
    "        out_channels: int = None,\n",
    "        num_repetitions: int = 1,\n",
    "        parameter_fn: nn.Module = None,\n",
    "        validate_args: bool | None = True,\n",
    "        border: Tensor = None,\n",
    "    ):\n",
    "        \"\"\"Initialize Normal distribution.\n",
    "\n",
    "        Args:\n",
    "            scope: Variable scope (Scope, int, or list[int]).\n",
    "            out_channels: Number of output channels (inferred from params if None).\n",
    "            num_repetitions: Number of repetitions (for 3D event shapes).\n",
    "            parameter_fn: Optional neural network for parameter generation.\n",
    "            border: Border tensor that separates the value interval.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            scope=scope,\n",
    "            out_channels=out_channels,\n",
    "            num_repetitions=num_repetitions,\n",
    "            params=[border],\n",
    "            parameter_fn=parameter_fn,\n",
    "            validate_args=validate_args,\n",
    "        )\n",
    "\n",
    "        border = init_parameter(param=border, event_shape=self._event_shape, init=torch.randn) * 10\n",
    "        border = torch.clamp(border, -10.0, 10.0)\n",
    "\n",
    "        self.border = nn.Parameter(border)\n",
    "\n",
    "    @property\n",
    "    def _supported_value(self):\n",
    "        return 0.0\n",
    "\n",
    "    @property\n",
    "    def _torch_distribution_class(self) -> type[torch.distributions.Normal]:\n",
    "        return _CustomLeafDistribution\n",
    "\n",
    "    def params(self):\n",
    "        return {\"border\": self.border}\n",
    "\n",
    "    def _compute_parameter_estimates(\n",
    "        self, data: Tensor, weights: Tensor, bias_correction: bool\n",
    "    ) -> dict[str, Tensor]:\n",
    "        \"\"\"Compute raw MLE estimates for normal distribution (without broadcasting).\n",
    "\n",
    "        Args:\n",
    "            data: Input data tensor.\n",
    "            weights: Weight tensor for each data point.\n",
    "            bias_correction: Whether to apply bias correction to variance estimate.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with 'loc' and 'scale' estimates (shape: out_features).\n",
    "        \"\"\"\n",
    "        return {\"border\": self.border}\n",
    "\n",
    "    def _set_mle_parameters(self, params_dict: dict[str, Tensor]) -> None:\n",
    "        \"\"\"Set MLE-estimated parameters for Normal distribution.\n",
    "\n",
    "        Explicitly handles the two parameter types:\n",
    "        - loc: Direct nn.Parameter, update .data attribute\n",
    "        - scale: Property with setter, calls property setter which updates log_scale\n",
    "\n",
    "        Args:\n",
    "            params_dict: Dictionary with 'loc' and 'scale' parameter values.\n",
    "        \"\"\"\n",
    "        self.border.data = params_dict[\"border\"]\n",
    "        self.scale = params_dict[\"scale\"]  # Uses property setter\n",
    "\n",
    "    def _mle_update_statistics(self, data: Tensor, weights: Tensor, bias_correction: bool) -> None:\n",
    "        \"\"\"Compute weighted mean and standard deviation.\n",
    "\n",
    "        Args:\n",
    "            data: Input data tensor.\n",
    "            weights: Weight tensor for each data point.\n",
    "            bias_correction: Whether to apply bias correction to variance estimate.\n",
    "        \"\"\"\n",
    "        estimates = self._compute_parameter_estimates(data, weights, bias_correction)\n",
    "\n",
    "        # Broadcast to event_shape and assign directly\n",
    "        self.border.data = self._broadcast_to_event_shape(estimates[\"border\"])\n",
    "\n",
    "\n",
    "class _CustomLeafDistribution:\n",
    "    \"\"\"Custom Hypergeometric distribution implementation.\n",
    "\n",
    "    Since PyTorch doesn't have a built-in Hypergeometric distribution,\n",
    "    this class implements the necessary methods for inference and sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, border: torch.Tensor, validate_args: bool = True):\n",
    "        self.border = torch.nn.Parameter(torch.tensor(border))\n",
    "        self.event_shape = border.shape\n",
    "        self.validate_args = validate_args\n",
    "\n",
    "    def _clamped_border(self):\n",
    "        # Ensure border stays inside the allowed interval\n",
    "        return torch.clamp(self.border, -10.0, 10.0)\n",
    "\n",
    "    def check_support(self, data: Tensor) -> Tensor:\n",
    "        \"\"\"Hypergeometric support: integer counts within valid borders.\n",
    "\n",
    "        Valid range: max(0, n+K-N) <= x <= min(n, K)\n",
    "        \"\"\"\n",
    "        valid = torch.all((data >= -10.0) & (data <= 10.0))\n",
    "\n",
    "        return valid\n",
    "\n",
    "    @property\n",
    "    def mode(self):\n",
    "        \"\"\"Return the mode of the distribution.\"\"\"\n",
    "        return self._clamped_border()\n",
    "\n",
    "    def log_prob(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute log probability using logarithmic identities to avoid overflow.\"\"\"\n",
    "\n",
    "        if self.validate_args:\n",
    "            support_mask = self.check_support(data)\n",
    "\n",
    "        border = self._clamped_border()\n",
    "\n",
    "        result = torch.where(data >= border, torch.log(torch.full_like(data, 0.3)), torch.log(torch.full_like(data, 0.7)))\n",
    "        result = result.masked_fill(~support_mask, float(\"-inf\"))\n",
    "        return result\n",
    "\n",
    "    def sample(self, n_samples):\n",
    "        \"\"\"\n",
    "        Sample `n_samples` draws.\n",
    "        Returns shape: (n_samples,)\n",
    "        Values are 10 if sample >= border, otherwise 0.\n",
    "        \"\"\"\n",
    "        if not isinstance(n_samples, tuple):\n",
    "            n_samples = (n_samples,)\n",
    "\n",
    "        # Prepare the tensor to store the samples\n",
    "        sample_shape = n_samples + self.event_shape\n",
    "\n",
    "        device = self.border.device\n",
    "        region_mask = torch.rand(sample_shape, device=device) < 0.7\n",
    "        border = self.border.expand(sample_shape)\n",
    "\n",
    "        # Step 2: allocate output\n",
    "        samples = torch.empty(sample_shape, device=device)\n",
    "\n",
    "        # Step 3: sample each region element-wise\n",
    "        # Upper region: U(border[i], high)\n",
    "        if region_mask.any():\n",
    "            samples[region_mask] = (\n",
    "                border[region_mask]\n",
    "                + torch.rand_like(border[region_mask]) * (10 - border[region_mask])\n",
    "            )\n",
    "\n",
    "        # Lower region: U(low, border[i])\n",
    "        if (~region_mask).any():\n",
    "            samples[~region_mask] = (\n",
    "                -10\n",
    "                + torch.rand_like(border[~region_mask]) * (border[~region_mask] - -10)\n",
    "            )\n",
    "\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.5437],\n",
      "         [ 6.0723]]])\n",
      "torch.Size([10, 1])\n",
      "tensor([[-4.6417],\n",
      "        [-2.4039],\n",
      "        [ 1.2206],\n",
      "        [-2.7092],\n",
      "        [-6.9326],\n",
      "        [ 2.9362],\n",
      "        [ 7.5226],\n",
      "        [ 7.3942],\n",
      "        [ 0.7955],\n",
      "        [-8.7497]], grad_fn=<IndexPutBackward0>)\n",
      "tensor([[ 9.2375],\n",
      "        [ 8.1393],\n",
      "        [-6.0355],\n",
      "        [ 1.0856],\n",
      "        [-3.1894]])\n",
      "Parameter containing:\n",
      "tensor([[[-6.5437],\n",
      "         [ 6.0723]]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex_\\AppData\\Local\\Temp\\ipykernel_28124\\3503048532.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.border = torch.nn.Parameter(torch.tensor(border))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.5437],\n",
       "         [ 6.0723]]], grad_fn=<ClampBackward1>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spflow.meta import Scope\n",
    "scope = Scope([0])\n",
    "custom_leaf = CustomLeaf(scope=scope, out_channels=2)\n",
    "samples = custom_leaf.sample(num_samples=10)\n",
    "print(custom_leaf.border.data)\n",
    "print(samples.shape)\n",
    "print(samples)\n",
    "\n",
    "data = -10 + 20 * torch.rand(5, 1)\n",
    "ll = custom_leaf.log_likelihood(data)\n",
    "print(data)\n",
    "print(custom_leaf.border)\n",
    "ll\n",
    "custom_leaf.mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Modules\n",
    "\n",
    "Each intermediate module receives one or more input modules. Every module in the library is designed to process exactly one input. Therefore, if you want to pass multiple modules as input, you must first concatenate them using the `Cat` module.\n",
    "\n",
    "All modules must implement the abstract properties and methods defined in the base `Module` class.\n",
    "\n",
    "### Required Methods\n",
    "\n",
    "1. **log_likelihood**\n",
    "2. **sample**\n",
    "3. **marginalize**\n",
    "\n",
    "### Required Properties\n",
    "\n",
    "1. **out_features**\n",
    "2. **out_channels**\n",
    "3. **feature_to_scope**\n",
    "\n",
    "Whether these properties can be inferred internally or must be provided explicitly at construction time depends on the module type.\n",
    "\n",
    "For example, a **Sum** module typically requires additional parameters such as:\n",
    "- number of output channels,\n",
    "- number of repetitions,\n",
    "- an optional weight tensor,\n",
    "- the summation dimension.\n",
    "\n",
    "A normal **Product** module, on the other hand, always has the same number of output channels as its input, so this value cannot (and does not need to) be specified manually.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Example: Implementing a Custom `SquaredSum` Module\n",
    "\n",
    "In this section we implement a custom `SquaredSum` module. Conceptually, it behaves like a standard sum module, except that it squares its inputs before summing them.\n",
    "\n",
    "The `SquaredSum` class inherits from the base `Module` class (although inheriting from the existing `Sum` module would also be possible). For clarity, we use the base class as our starting point.\n",
    "\n",
    "Because this is a sum-like module, we introduce a weight tensor. The most common shape for such weights is:\n",
    "\n",
    "(out_features, in_channels, out_channels, num_repetitions)\n",
    "\n",
    "\n",
    "These weights are trainable parameters and therefore must be registered. To avoid unwanted behavior, the module performs several checks to ensure that:\n",
    "\n",
    "- the weight tensor has the correct shape,\n",
    "- all weights are positive,\n",
    "- and the weights are normalized to sum to 1.\n",
    "\n",
    "---\n",
    "\n",
    "## `log_likelihood`\n",
    "\n",
    "The `log_likelihood` method begins by initializing the module's cache, which stores computed log-likelihoods for later use (e.g., during sampling).\n",
    "\n",
    "The log-likelihood produced by any module always has the shape:\n",
    "\n",
    "(batch_size, out_features, out_channels, num_repetitions)\n",
    "\n",
    "\n",
    "You can rely on this shape when accessing the output of the input module.\n",
    "\n",
    "For the `SquaredSum` module, the log-likelihood computation consists of taking a weighted squared sum of the input log-likelihoods. The returned tensor must again match the standard shape:\n",
    "\n",
    "(batch_size, out_features, out_channels, num_repetitions)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## `sample`\n",
    "\n",
    "Sampling in this library relies on a **sampling context**.  \n",
    "This context is propagated from the root module toward the leaf modules and contains, for each feature, the selected **channel** and **repetition** indices. Each module must implement its own logic for mapping the channel index in the context to the channel index expected by its input module.\n",
    "\n",
    "The repetition index is chosen at the root and remains unchanged throughout propagation.\n",
    "\n",
    "For the `SquaredSum` module, the sampling procedure works as follows:\n",
    "\n",
    "1. Extract the weight slice associated with the repetition index stored in the context.  \n",
    "2. Check whether log-likelihoods are available in the cache for conditional sampling.  \n",
    "3. If performing MPE sampling, select the channel indices with the highest logits.  \n",
    "4. Otherwise, draw channel indices using a categorical distribution over the logits.  \n",
    "5. Update the sampling context with the newly selected indices.  \n",
    "6. Pass the updated context to the input module to continue the sampling process.\n",
    "\n",
    "---\n",
    "\n",
    "## `marginalize`\n",
    "\n",
    "The `marginalize` method structurally marginalizes the module by removing the specified random variables from the layer. This process involves not only updating the scope but also adapting any parameters that depend on the number of features in the layer. If the entire scope is marginalized, the method is expected to return `None`. Otherwise, it should return a new module with updated parameters and marginalized input modules.\n",
    "\n",
    "In the `SquaredSum` layer, we begin by calling `marginalize` on the input module to obtain its marginalized version. Next, we marginalize the sum layer itself using the `feature_to_scope` property, which enables us to remove the appropriate feature column from the weight matrix. We then construct a new `SquaredSum` module using the marginalized input module and the updated weight matrix as the layer’s weights. From these updated weights, the new scope can be derived as described earlier. Finally, we return the marginalized `SquaredSum` layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from spflow.exceptions import InvalidParameterCombinationError\n",
    "from spflow.modules.base import Module\n",
    "from spflow.modules.ops.cat import Cat\n",
    "from spflow.utils.cache import Cache, cached\n",
    "from spflow.utils.projections import (\n",
    "    proj_convex_to_real,\n",
    ")\n",
    "from spflow.utils.sampling_context import SamplingContext, init_default_sampling_context\n",
    "\n",
    "\n",
    "class SquaredSum(Module):\n",
    "    \"\"\"Sum module representing mixture operations in probabilistic circuits.\n",
    "\n",
    "    Implements mixture modeling by computing weighted combinations of child distributions.\n",
    "    Weights are normalized to sum to one, maintaining valid probability distributions.\n",
    "    Supports both single input (mixture over channels) and multiple inputs (mixture\n",
    "    over concatenated inputs).\n",
    "\n",
    "    Attributes:\n",
    "        inputs (Module): Input module(s) to the sum node.\n",
    "        sum_dim (int): Dimension over which to sum the inputs.\n",
    "        weights (Tensor): Normalized weights for mixture components.\n",
    "        logits (Parameter): Unnormalized log-weights for gradient optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputs: Module | list[Module],\n",
    "        out_channels: int | None = None,\n",
    "        num_repetitions: int = 1,\n",
    "        weights: Tensor | list[float] | None = None,\n",
    "        sum_dim: int | None = 1,\n",
    "    ) -> None:\n",
    "        \"\"\"Create a Sum module for mixture modeling.\n",
    "\n",
    "        Weights are automatically normalized to sum to one using softmax.\n",
    "        Multiple inputs are concatenated along dimension 2 internally.\n",
    "\n",
    "        Args:\n",
    "            inputs (Module | list[Module]): Single module or list of modules to mix.\n",
    "            out_channels (int | None, optional): Number of output mixture components.\n",
    "                Required if weights not provided.\n",
    "            num_repetitions (int | None, optional): Number of repetitions for structured\n",
    "                representations. Inferred from weights if not provided.\n",
    "            weights (Tensor | list[float] | None, optional): Initial mixture weights.\n",
    "                Must have compatible shape with inputs and out_channels.\n",
    "            sum_dim (int | None, optional): Dimension over which to sum inputs. Default is 1.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If inputs empty, out_channels < 1, or weights have invalid shape/values.\n",
    "            InvalidParameterCombinationError: If both out_channels and weights are specified.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # ========== 1. INPUT VALIDATION ==========\n",
    "        if not inputs:\n",
    "            raise ValueError(\"'Sum' requires at least one input to be specified.\")\n",
    "\n",
    "        # Convert weights from list to tensor if needed\n",
    "        if weights is not None and isinstance(weights, list):\n",
    "            weights = torch.tensor(weights)\n",
    "\n",
    "        # ========== 2. WEIGHTS PARAMETER PROCESSING ==========\n",
    "        if weights is not None:\n",
    "            # Validate mutual exclusivity with out_channels\n",
    "            if out_channels is not None:\n",
    "                raise InvalidParameterCombinationError(\n",
    "                    f\"Cannot specify both 'out_channels' and 'weights' for 'Sum' module.\"\n",
    "                )\n",
    "\n",
    "            # Validate num_repetitions compatibility\n",
    "            if num_repetitions is not None and (num_repetitions != 1 and num_repetitions != weights.shape[-1]):\n",
    "                raise InvalidParameterCombinationError(\n",
    "                    f\"Cannot specify 'num_repetitions' that does not match weights shape for 'Sum' module. \"\n",
    "                    f\"Was {num_repetitions} but weights shape indicates {weights.shape[-1]}.\"\n",
    "                )\n",
    "\n",
    "            # Reshape weights to canonical 4D form: (out_features, in_channels, out_channels, num_repetitions)\n",
    "            weight_dim = weights.dim()\n",
    "            if weight_dim == 1:\n",
    "                weights = weights.view(1, -1, 1)\n",
    "            elif weight_dim == 2:\n",
    "                weights = weights.view(1, weights.shape[0], weights.shape[1])\n",
    "            elif weight_dim == 3:\n",
    "                pass  # Already 3D, will add repetition dimension below\n",
    "            elif weight_dim == 4:\n",
    "                pass  # Already 4D\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Weights for 'Sum' must be a 1D, 2D, 3D, or 4D tensor but was {weight_dim}D.\"\n",
    "                )\n",
    "\n",
    "            # Derive configuration from weights shape\n",
    "            out_channels = weights.shape[2]\n",
    "            num_repetitions = weights.shape[3]\n",
    "\n",
    "        # ========== 3. CONFIGURATION VALIDATION ==========\n",
    "        if out_channels < 1:\n",
    "            raise ValueError(\n",
    "                f\"Number of nodes for 'Sum' must be greater of equal to 1 but was {out_channels}.\"\n",
    "            )\n",
    "\n",
    "        # Validate sum_dim compatibility with weights dimensionality\n",
    "        if weights is not None:\n",
    "            max_sum_dim = weights.dim() - 1\n",
    "            if sum_dim > max_sum_dim:\n",
    "                raise ValueError(\n",
    "                    f\"When providing {weights.dim()}D weights, 'sum_dim' must be at most {max_sum_dim} but was {sum_dim}.\"\n",
    "                )\n",
    "\n",
    "        # ========== 4. INPUT MODULE SETUP ==========\n",
    "        if isinstance(inputs, list):\n",
    "            if len(inputs) == 1:\n",
    "                self.inputs = inputs[0]\n",
    "            else:\n",
    "                self.inputs = Cat(inputs=inputs, dim=2)\n",
    "        else:\n",
    "            self.inputs = inputs\n",
    "\n",
    "        self.sum_dim = sum_dim\n",
    "\n",
    "        # ========== 5. ATTRIBUTE INITIALIZATION ==========\n",
    "        self._out_features = self.inputs.out_features\n",
    "        self._in_channels_total = self.inputs.out_channels\n",
    "        self._out_channels_total = out_channels\n",
    "        self.num_repetitions = num_repetitions\n",
    "\n",
    "        self.weights_shape = (\n",
    "            self._out_features,\n",
    "            self._in_channels_total,\n",
    "            self._out_channels_total,\n",
    "            self.num_repetitions,\n",
    "        )\n",
    "\n",
    "        self.scope = self.inputs.scope\n",
    "\n",
    "        # ========== 6. WEIGHT INITIALIZATION & PARAMETER REGISTRATION ==========\n",
    "        if weights is None:\n",
    "            # Initialize weights randomly with small epsilon to avoid zeros\n",
    "            weights = torch.rand(self.weights_shape) + 1e-08\n",
    "            # Normalize to sum to one along sum_dim\n",
    "            weights /= torch.sum(weights, dim=self.sum_dim, keepdims=True)\n",
    "\n",
    "        # Register parameter for unnormalized log-probabilities\n",
    "        self.logits = torch.nn.Parameter()\n",
    "\n",
    "        # Set weights (converts to logits internally via property setter)\n",
    "        self.weights = weights\n",
    "\n",
    "    @property\n",
    "    def feature_to_scope(self) -> np.ndarray:\n",
    "        return self.inputs.feature_to_scope\n",
    "\n",
    "    @property\n",
    "    def out_features(self) -> int:\n",
    "        return self._out_features\n",
    "\n",
    "    @property\n",
    "    def out_channels(self) -> int:\n",
    "        return self._out_channels_total\n",
    "\n",
    "    @property\n",
    "    def log_weights(self) -> Tensor:\n",
    "        \"\"\"Returns the log weights of all nodes as a tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Log weights normalized to sum to one.\n",
    "        \"\"\"\n",
    "        # project auxiliary weights onto weights that sum up to one\n",
    "        return torch.nn.functional.log_softmax(self.logits, dim=self.sum_dim)\n",
    "\n",
    "    @property\n",
    "    def weights(self) -> Tensor:\n",
    "        \"\"\"Returns the weights of all nodes as a tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Weights normalized to sum to one.\n",
    "        \"\"\"\n",
    "        # project auxiliary weights onto weights that sum up to one\n",
    "        return torch.nn.functional.softmax(self.logits, dim=self.sum_dim)\n",
    "\n",
    "    @weights.setter\n",
    "    def weights(\n",
    "        self,\n",
    "        values: Tensor,\n",
    "    ) -> None:\n",
    "        \"\"\"Set weights of all nodes.\n",
    "\n",
    "        Args:\n",
    "            values: Tensor containing weights for each input and node.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If weights have invalid shape, contain non-positive values,\n",
    "                or do not sum to one.\n",
    "        \"\"\"\n",
    "        if values.shape != self.weights_shape:\n",
    "            raise ValueError(\n",
    "                f\"Invalid shape for weights: Was {values.shape} but expected {self.weights_shape}.\"\n",
    "            )\n",
    "        if not torch.all(values > 0):\n",
    "            raise ValueError(\"Weights for 'Sum' must be all positive.\")\n",
    "        if not torch.allclose(torch.sum(values, dim=self.sum_dim), torch.tensor(1.0)):\n",
    "            raise ValueError(\"Weights for 'Sum' must sum up to one.\")\n",
    "        self.logits.data = proj_convex_to_real(values)\n",
    "\n",
    "    @log_weights.setter\n",
    "    def log_weights(\n",
    "        self,\n",
    "        values: Tensor,\n",
    "    ) -> None:\n",
    "        \"\"\"Set log weights of all nodes.\n",
    "\n",
    "        Args:\n",
    "            values: Tensor containing log weights for each input and node.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If log weights have invalid shape.\n",
    "        \"\"\"\n",
    "        if values.shape != self.log_weights.shape:\n",
    "            raise ValueError(f\"Invalid shape for weights: {values.shape}.\")\n",
    "        self.logits.data = values\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"{super().extra_repr()}, weights={self.weights_shape}\"\n",
    "\n",
    "    @cached\n",
    "    def log_likelihood(\n",
    "        self,\n",
    "        data: Tensor,\n",
    "        cache: Cache | None = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Compute log likelihood P(data | module).\n",
    "\n",
    "        Computes log likelihood using logsumexp for numerical stability.\n",
    "        Results are cached for parameter learning algorithms.\n",
    "\n",
    "        Args:\n",
    "            data: Input data of shape (batch_size, num_features).\n",
    "                NaN values indicate evidence for conditional computation.\n",
    "            cache: Cache for intermediate computations. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Log-likelihood of shape (batch_size, num_features, out_channels)\n",
    "                or (batch_size, num_features, out_channels, num_repetitions).\n",
    "        \"\"\"\n",
    "        if cache is None:\n",
    "            cache = Cache()\n",
    "\n",
    "        # Get input log-likelihoods\n",
    "        ll = self.inputs.log_likelihood(\n",
    "            data,\n",
    "            cache=cache,\n",
    "        )\n",
    "\n",
    "        ll = ll.unsqueeze(3)\n",
    "\n",
    "        squared_ll = ll * 2# shape: (B, F, input_OC, R)\n",
    "\n",
    "        log_weights = self.log_weights.unsqueeze(0)  # shape: (1, F, IC, OC, R)\n",
    "\n",
    "        # Weighted log-likelihoods\n",
    "        weighted_lls = squared_ll + log_weights  # shape: (B, F, IC, OC, R)\n",
    "\n",
    "        # Sum over input channels (sum_dim + 1 since here the batch dimension is the first dimension)\n",
    "        output = torch.logsumexp(weighted_lls, dim=self.sum_dim + 1)\n",
    "\n",
    "        batch_size = output.shape[0]\n",
    "        result = output.view(batch_size, self.out_features, self.out_channels, self.num_repetitions)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        num_samples: int | None = None,\n",
    "        data: Tensor | None = None,\n",
    "        is_mpe: bool = False,\n",
    "        cache: Cache | None = None,\n",
    "        sampling_ctx: SamplingContext | None = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Generate samples from sum module.\n",
    "\n",
    "        Args:\n",
    "            num_samples: Number of samples to generate.\n",
    "            data: Data tensor with NaN values to fill with samples.\n",
    "            is_mpe: Whether to perform maximum a posteriori estimation.\n",
    "            cache: Optional cache dictionary.\n",
    "            sampling_ctx: Optional sampling context.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Sampled values.\n",
    "        \"\"\"\n",
    "        if cache is None:\n",
    "            cache = Cache()\n",
    "\n",
    "        # Handle num_samples case (create empty data tensor)\n",
    "        if data is None:\n",
    "            if num_samples is None:\n",
    "                num_samples = 1\n",
    "            data = torch.full((num_samples, len(self.scope.query)), float(\"nan\")).to(self.device)\n",
    "\n",
    "        # Initialize sampling context if not provided\n",
    "        sampling_ctx = init_default_sampling_context(sampling_ctx, data.shape[0], data.device)\n",
    "\n",
    "        # Index into the correct weight channels given by parent module\n",
    "        if sampling_ctx.repetition_idx is not None:\n",
    "            logits = self.logits.unsqueeze(0).expand(\n",
    "                sampling_ctx.channel_index.shape[0], -1, -1, -1, -1\n",
    "            )  # shape [b , n_features , in_c, out_c, r]\n",
    "\n",
    "            indices = sampling_ctx.repetition_idx  # Shape (30000, 1)\n",
    "\n",
    "            # Use gather to select the correct repetition\n",
    "            # Repeat indices to match the target dimension for gathering\n",
    "            in_channels_total = logits.shape[2]\n",
    "            indices = indices.view(-1, 1, 1, 1, 1).expand(\n",
    "                -1, logits.shape[1], in_channels_total, logits.shape[3], -1\n",
    "            )\n",
    "            # Gather the logits based on the repetition indices\n",
    "            logits = torch.gather(logits, dim=-1, index=indices).squeeze(-1)\n",
    "\n",
    "        else:\n",
    "            if self.num_repetitions > 1:\n",
    "                raise ValueError(\n",
    "                    \"sampling_ctx.repetition_idx must be provided when sampling from a module with \"\n",
    "                    \"num_repetitions > 1.\"\n",
    "                )\n",
    "            logits = self.logits[..., 0] # Select the 0th repetition\n",
    "            logits = logits.unsqueeze(0) # Make space for the batch\n",
    "\n",
    "            # Expand to batch size\n",
    "            logits = logits.expand(sampling_ctx.channel_index.shape[0], -1, -1, -1)\n",
    "\n",
    "        idxs = sampling_ctx.channel_index[..., None, None]\n",
    "        in_channels_total = logits.shape[2]\n",
    "        idxs = idxs.expand(-1, -1, in_channels_total, -1)\n",
    "        # Gather the logits based on the channel indices\n",
    "        logits = logits.gather(dim=3, index=idxs).squeeze(3)\n",
    "\n",
    "        # Check if evidence is given (cached log-likelihoods)\n",
    "        if (\n",
    "            cache is not None\n",
    "            and \"log_likelihood\" in cache\n",
    "            and cache[\"log_likelihood\"].get(self.inputs) is not None\n",
    "        ):\n",
    "            # Get the log likelihoods from the cache\n",
    "            input_lls = cache[\"log_likelihood\"][self.inputs]\n",
    "\n",
    "            if sampling_ctx.repetition_idx is not None:\n",
    "                indices = sampling_ctx.repetition_idx.view(-1, 1, 1, 1).expand(\n",
    "                    -1, input_lls.shape[1], input_lls.shape[2], -1\n",
    "                )\n",
    "\n",
    "                # Use gather to select the correct repetition\n",
    "                input_lls = torch.gather(input_lls, dim=-1, index=indices).squeeze(-1)\n",
    "\n",
    "                log_prior = logits\n",
    "                log_posterior = log_prior + input_lls\n",
    "                log_posterior = log_posterior.log_softmax(dim=2)\n",
    "                logits = log_posterior\n",
    "            else:\n",
    "                log_prior = logits\n",
    "                log_posterior = log_prior + input_lls\n",
    "                log_posterior = log_posterior.log_softmax(dim=2)\n",
    "                logits = log_posterior\n",
    "\n",
    "        # Sample from categorical distribution defined by weights to obtain indices into input channels\n",
    "        if is_mpe:\n",
    "            # Take the argmax of the logits to obtain the most probable index\n",
    "            sampling_ctx.channel_index = torch.argmax(logits, dim=-1)\n",
    "        else:\n",
    "            # Sample from categorical distribution defined by weights to obtain indices into input channels\n",
    "            sampling_ctx.channel_index = torch.distributions.Categorical(logits=logits).sample()\n",
    "\n",
    "        # Sample from input module\n",
    "        self.inputs.sample(\n",
    "            data=data,\n",
    "            is_mpe=is_mpe,\n",
    "            cache=cache,\n",
    "            sampling_ctx=sampling_ctx,\n",
    "        )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def expectation_maximization(\n",
    "        self,\n",
    "        data: Tensor,\n",
    "        cache: Cache | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Perform expectation-maximization step.\n",
    "\n",
    "        Args:\n",
    "            data: Input data tensor.\n",
    "            cache: Optional cache dictionary with log-likelihoods.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If required log-likelihoods are not found in cache.\n",
    "        \"\"\"\n",
    "        if cache is None:\n",
    "            cache = Cache()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # ----- expectation step -----\n",
    "\n",
    "            # Get input LLs from cache\n",
    "            input_lls = cache[\"log_likelihood\"].get(self.inputs)\n",
    "            if input_lls is None:\n",
    "                raise ValueError(\"Input log-likelihoods not found in cache. Call log_likelihood first.\")\n",
    "\n",
    "            # Get module lls from cache\n",
    "            module_lls = cache[\"log_likelihood\"].get(self)\n",
    "            if module_lls is None:\n",
    "                raise ValueError(\"Module log-likelihoods not found in cache. Call log_likelihood first.\")\n",
    "\n",
    "            log_weights = self.log_weights.unsqueeze(0)\n",
    "            log_grads = torch.log(module_lls.grad).unsqueeze(2)\n",
    "            input_lls = input_lls.unsqueeze(3)\n",
    "            module_lls = module_lls.unsqueeze(2)\n",
    "\n",
    "            log_expectations = log_weights + log_grads + input_lls - module_lls\n",
    "            log_expectations = log_expectations.logsumexp(0)  # Sum over batch dimension\n",
    "            log_expectations = log_expectations.log_softmax(self.sum_dim)  # Normalize\n",
    "\n",
    "            # ----- maximization step -----\n",
    "            self.log_weights = log_expectations\n",
    "\n",
    "        # Recursively call EM on inputs\n",
    "        self.inputs.expectation_maximization(data, cache=cache)\n",
    "\n",
    "    def maximum_likelihood_estimation(\n",
    "        self,\n",
    "        data: Tensor,\n",
    "        weights: Tensor | None = None,\n",
    "        cache: Cache | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Update parameters via maximum likelihood estimation.\n",
    "\n",
    "        For Sum modules, this is equivalent to EM.\n",
    "\n",
    "        Args:\n",
    "            data: Input data tensor.\n",
    "            weights: Optional sample weights (currently unused).\n",
    "            cache: Optional cache dictionary.\n",
    "        \"\"\"\n",
    "        self.expectation_maximization(data, cache=cache)\n",
    "\n",
    "    def marginalize(\n",
    "        self,\n",
    "        marg_rvs: list[int],\n",
    "        prune: bool = True,\n",
    "        cache: Cache | None = None,\n",
    "    ) -> SquaredSum | None:\n",
    "        \"\"\"Marginalize out specified random variables.\n",
    "\n",
    "        Args:\n",
    "            marg_rvs: List of random variables to marginalize.\n",
    "            prune: Whether to prune the module.\n",
    "            cache: Optional cache dictionary.\n",
    "\n",
    "        Returns:\n",
    "            Marginalized Sum module or None.\n",
    "        \"\"\"\n",
    "        if cache is None:\n",
    "            cache = Cache()\n",
    "\n",
    "        # compute module scope (same for all outputs)\n",
    "        module_scope = self.scope\n",
    "        marg_input = None\n",
    "\n",
    "        mutual_rvs = set(module_scope.query).intersection(set(marg_rvs))\n",
    "        module_weights = self.weights\n",
    "\n",
    "        # module scope is being fully marginalized over\n",
    "        if len(mutual_rvs) == len(module_scope.query):\n",
    "            # passing this loop means marginalizing over the whole scope of this branch\n",
    "            return None\n",
    "\n",
    "        # node scope is being partially marginalized\n",
    "        elif mutual_rvs:\n",
    "            # marginalize input modules\n",
    "            marg_input = self.inputs.marginalize(marg_rvs, prune=prune, cache=cache)\n",
    "\n",
    "            # if marginalized input is not None\n",
    "            if marg_input:\n",
    "                # Apply mask to weights per-repetition\n",
    "                masked_weights_list = []\n",
    "                for r in range(self.num_repetitions):\n",
    "                    feature_to_scope_r = self.inputs.feature_to_scope[:, r].copy()\n",
    "                    # remove mutual_rvs from feature_to_scope list\n",
    "                    for rv in mutual_rvs:\n",
    "                        for idx, scope in enumerate(feature_to_scope_r):\n",
    "                            if scope is not None:\n",
    "                                if rv in scope.query:\n",
    "                                    feature_to_scope_r[idx] = scope.remove_from_query(rv)\n",
    "\n",
    "                    # construct mask with empty scopes\n",
    "                    mask = torch.tensor([not scope.empty() for scope in feature_to_scope_r], device=self.device).bool()\n",
    "\n",
    "                    # Apply mask to weights for this repetition: (out_features, in_channels, out_channels)\n",
    "                    masked_weights_r = module_weights[:, :, :, r][mask]\n",
    "                    masked_weights_list.append(masked_weights_r)\n",
    "\n",
    "                # Stack weights back along the repetition dimension\n",
    "                # Handle different repetition counts if needed\n",
    "                if all(w.shape[0] == masked_weights_list[0].shape[0] for w in masked_weights_list):\n",
    "                    # All repetitions have same number of features, can stack directly\n",
    "                    module_weights = torch.stack(masked_weights_list, dim=-1)\n",
    "                else:\n",
    "                    # Features differ across repetitions - this shouldn't happen in practice\n",
    "                    # but handle gracefully by keeping the largest\n",
    "                    max_features = max(w.shape[0] for w in masked_weights_list)\n",
    "                    padded_list = []\n",
    "                    for w in masked_weights_list:\n",
    "                        if w.shape[0] < max_features:\n",
    "                            padding = torch.zeros(\n",
    "                                max_features - w.shape[0], w.shape[1], w.shape[2],\n",
    "                                device=w.device, dtype=w.dtype\n",
    "                            )\n",
    "                            w = torch.cat([w, padding], dim=0)\n",
    "                        padded_list.append(w)\n",
    "                    module_weights = torch.stack(padded_list, dim=-1)\n",
    "\n",
    "        else:\n",
    "            marg_input = self.inputs\n",
    "\n",
    "        if marg_input is None:\n",
    "            return None\n",
    "\n",
    "        else:\n",
    "            return SquaredSum(inputs=marg_input, weights=module_weights, sum_dim=self.sum_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Modules\n",
    "\n",
    "At the end of this guide, we take a look at a rather unique type of intermediate module: the **Split module**. A Split module receives a single module as input and produces multiple outputs by splitting it in a defined way. This becomes relevant whenever a module requires multiple inputs—for example, the elementwise product module, which computes the elementwise product of two or more input modules.\n",
    "\n",
    "Since there are many possible ways to split a module, the following explanation provides guidance on how to create your own Split module adjusted to your specific splitting strategy.\n",
    "\n",
    "Split modules inherit from the base `Split` class, where `out_features` and `out_channels` are already defined. Conceptually, a Split module represents a different *view* of an existing module. Therefore, `out_features` and `out_channels` always match those of the input module. However, you must implement the mapping from feature index to scope in the `feature_to_scope` property. And because Split modules only provide an alternative view, the only method that must be implemented is `log_likelihood`.\n",
    "\n",
    "A Split module takes:\n",
    "- a single input module,\n",
    "- the dimension along which the split should occur,\n",
    "- and the number of splits, which determines how many groups the input module should be divided into.\n",
    "\n",
    "In the example below, we implement a **pairwise alternating split**. For instance, if we split along the feature dimension into two groups and the features are:\n",
    "\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "\n",
    "then the resulting split would be:\n",
    "\n",
    "- Group 1: `[0, 1, 4, 5, 8, 9]`  \n",
    "- Group 2: `[2, 3, 6, 7]`\n",
    "\n",
    "For efficient evaluation of `log_likelihood`, the most common numbers of splits (2 and 3) are implemented in a hard-coded fashion. Other numbers of splits are handled by constructing a mask during initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Alternating splitting operation for tensor partitioning.\n",
    "\n",
    "Distributes features in an alternating pattern across splits using modulo\n",
    "arithmetic. Promotes feature diversity across branches. Used in RAT-SPN\n",
    "and similar architectures.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from spflow.meta.data import Scope\n",
    "from spflow.modules.base import Module\n",
    "from spflow.modules.ops.split import Split\n",
    "from spflow.utils.cache import Cache, cached\n",
    "\n",
    "\n",
    "class SplitAlternatePairwise(Split):\n",
    "    \"\"\"Split operation using pairwise alternating feature distribution.\n",
    "\n",
    "    Distributes features pairwise: features (0,1) go to split 0, (2,3) go to split 1,\n",
    "    (4,5) go to split 2, then repeating modulo num_splits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputs: Module, dim: int = 1, num_splits: int | None = 2):\n",
    "        super().__init__(inputs=inputs, dim=dim, num_splits=num_splits)\n",
    "\n",
    "        num_f = inputs.out_features\n",
    "        device = inputs.device\n",
    "\n",
    "        # Pairwise alternating index assignment:\n",
    "        # For feature i, compute which pair it's in (i // 2), then modulo num_splits\n",
    "        pair_ids = (torch.arange(num_f, device=device) // 2) % num_splits\n",
    "\n",
    "        # Create masks for each split\n",
    "        self.split_masks = [pair_ids == i for i in range(num_splits)]\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"{super().extra_repr()}, dim={self.dim}\"\n",
    "\n",
    "    @property\n",
    "    def feature_to_scope(self) -> list[Scope]:\n",
    "        scopes = self.inputs[0].feature_to_scope\n",
    "        feature_to_scope = []\n",
    "\n",
    "        # pairwise selection: (0,1)->split0, (2,3)->split1, ...\n",
    "        for i in range(self.num_splits):\n",
    "            sub_scopes = [scopes[j] for j in range(len(scopes))\n",
    "                          if ((j // 2) % self.num_splits) == i]\n",
    "            feature_to_scope.append(sub_scopes)\n",
    "\n",
    "        return feature_to_scope\n",
    "\n",
    "    def _apply(self, fn):\n",
    "        super()._apply(fn)\n",
    "        self.split_masks = [fn(mask) for mask in self.split_masks]\n",
    "        return self\n",
    "\n",
    "    @cached\n",
    "    def log_likelihood(self, data: Tensor, cache: Cache | None = None) -> list[Tensor]:\n",
    "        lls = self.inputs[0].log_likelihood(data, cache=cache)\n",
    "\n",
    "        if self.num_splits == 1:\n",
    "            return [lls]\n",
    "\n",
    "        # Hard-code pairwise versions for common cases\n",
    "        if self.num_splits == 2:\n",
    "            # pairs: (0,1)->0, (2,3)->1, ...\n",
    "            return [\n",
    "                lls[:, [i for i in range(lls.shape[1]) if (i // 2) % 2 == 0], ...],\n",
    "                lls[:, [i for i in range(lls.shape[1]) if (i // 2) % 2 == 1], ...]\n",
    "            ]\n",
    "\n",
    "        elif self.num_splits == 3:\n",
    "            return [\n",
    "                lls[:, [i for i in range(lls.shape[1]) if (i // 2) % 3 == 0], ...],\n",
    "                lls[:, [i for i in range(lls.shape[1]) if (i // 2) % 3 == 1], ...],\n",
    "                lls[:, [i for i in range(lls.shape[1]) if (i // 2) % 3 == 2], ...]\n",
    "            ]\n",
    "\n",
    "        # General fallback: use masks computed in __init__\n",
    "        return [lls[:, mask, ...] for mask in self.split_masks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0], dtype=object), array([1], dtype=object), array([4], dtype=object)]\n",
      "[array([2], dtype=object), array([3], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "from tests.utils.leaves import make_normal_leaf, make_normal_data\n",
    "out_features = 5\n",
    "out_channels = 3\n",
    "num_reps = 1\n",
    "num_splits = 2\n",
    "scope = Scope(list(range(0, out_features)))\n",
    "\n",
    "inputs_a = make_normal_leaf(scope, out_channels=out_channels, num_repetitions=num_reps)\n",
    "\n",
    "module = SplitAlternatePairwise(inputs=inputs_a, num_splits=num_splits, dim=1)\n",
    "\n",
    "data = make_normal_data(out_features=module.out_features, num_samples=1)\n",
    "lls = module.log_likelihood(data)\n",
    "\n",
    "print(module.feature_to_scope[0])\n",
    "print(module.feature_to_scope[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}